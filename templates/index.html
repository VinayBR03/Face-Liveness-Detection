<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Face Liveness Detection</title>
  <style>
    body {
      font-family: sans-serif;
      background: #f0f2f5;
      text-align: center;
      margin-top: 2rem;
    }
    #main {
      background: white;
      padding: 2rem;
      border-radius: 8px;
      width: 460px;
      margin: auto;
      box-shadow: 0 4px 10px rgba(0,0,0,0.1);
      position: relative;
    }
    video {
      width: 400px;
      height: 300px;
      border-radius: 8px;
    }
    canvas {
      position: absolute;
      top: 0;
      left: 0;
    }
    button {
      padding: 10px 20px;
      color: white;
      border: none;
      border-radius: 5px;
      cursor: pointer;
      margin: 5px;
    }
    button:disabled {
      background-color: #cccccc;
      cursor: not-allowed;
    }
    #start-btn { background-color: #28a745; }
    #stop-btn { background-color: #dc3545; }
    #result { font-weight: bold; margin-top: 1rem; }
    #loader {
      display: none;
      border: 6px solid #f3f3f3;
      border-top: 6px solid #38a1db;
      border-radius: 50%;
      width: 40px;
      height: 40px;
      animation: spin 1s linear infinite;
      position: absolute;
      top: 130px;
      left: calc(50% - 20px);
      z-index: 10;
    }
    @keyframes spin {
      0% { transform: rotate(0deg); }
      100% { transform: rotate(360deg); }
    }
    #fps-counter {
      position: absolute;
      bottom: 8px;
      left: 10px;
      background: rgba(0,0,0,0.5);
      color: white;
      font-size: 14px;
      padding: 3px 6px;
      border-radius: 4px;
    }
  </style>
</head>
<body>
  <div id="main">
    <h2>Face Liveness Detection</h2>
    <div style="position: relative; display: inline-block;">
      <video id="video" autoplay muted playsinline></video>
      <canvas id="overlay" width="400" height="300"></canvas>
      <div id="loader"></div>
      <div id="fps-counter">FPS: 0</div>
    </div>
    <div>
      <button id="start-btn" disabled>Start</button>
      <button id="stop-btn" disabled>Stop</button>
    </div>
    <div id="result"></div>
  </div>

  <script>
  const video = document.getElementById("video");
  const overlay = document.getElementById("overlay");
  const ctx = overlay.getContext("2d");
  const startBtn = document.getElementById("start-btn");
  const stopBtn = document.getElementById("stop-btn");
  const resultDiv = document.getElementById("result");
  const loader = document.getElementById("loader");
  const fpsCounter = document.getElementById("fps-counter");

  const CLIP = 10;

  let frames = [];
  let sensors = [];
  let faceBoxesClip = [];
  let interval = null;
  let predictionText = "";
  let inflight = false;
  let lastFace = null;

  let lastTime = performance.now();
  let fps = 0;

  navigator.mediaDevices.getUserMedia({ video: true })
    .then(stream => {
      video.srcObject = stream;
      startBtn.disabled = false;
    })
    .catch(err => alert("Camera access denied: " + err));

  if (window.DeviceMotionEvent) {
    window.addEventListener("devicemotion", e => {
      sensors.push([
        (e.accelerationIncludingGravity?.x) || 0,
        (e.accelerationIncludingGravity?.y) || 0,
        (e.accelerationIncludingGravity?.z) || 0,
        0, 0, 0, 0, 0
      ]);
      if (sensors.length > CLIP) sensors.shift();
    });
  }

  async function detectFace(frameData) {
    const res = await fetch("/detect", {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({ image: frameData })
    });
    const out = await res.json();
    if (out.faces && out.faces.length > 0) {
      lastFace = out.faces[0];
    }
    return out;
  }

  async function processFrames() {
    if (inflight) return;
    if (frames.length < CLIP) return;

    inflight = true;
    loader.style.display = "block";

    try {
      const res = await fetch("/predict", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({
          image_clip: frames,
          sensor_clip: sensors,
          face_boxes: faceBoxesClip
        })
      });
      const data = await res.json();
      loader.style.display = "none";
      inflight = false;

      if (data.error) {
        resultDiv.textContent = data.error;
        resultDiv.style.color = "orange";
        return;
      }

      const score = data.liveness_score;
      if (typeof score !== "number" || !isFinite(score)) {
        resultDiv.textContent = "Invalid score";
        resultDiv.style.color = "orange";
        return;
      }

      if (data.reason === "Insufficient motion/variation") {
        predictionText = "Move head slightly";
        resultDiv.textContent = "Move head slightly";
        resultDiv.style.color = "orange";
        return;
      }

      if (score >= 0.90) {
        predictionText = `Real ${(score * 100).toFixed(1)}%`;
        resultDiv.style.color = "green";
      } else {
        predictionText = `Fake ${((1 - score) * 100).toFixed(1)}%`;
        resultDiv.style.color = "red";
      }
      resultDiv.textContent = predictionText;
    } catch (e) {
      loader.style.display = "none";
      inflight = false;
      resultDiv.textContent = "Prediction failed";
      resultDiv.style.color = "orange";
    }
  }

  startBtn.onclick = () => {
    startBtn.disabled = true;
    stopBtn.disabled = false;
    loader.style.display = "block";

    frames = [];
    sensors = [];
    faceBoxesClip = [];

    interval = setInterval(async () => {
      const now = performance.now();
      fps = 1000 / (now - lastTime);
      lastTime = now;
      fpsCounter.textContent = "FPS: " + fps.toFixed(1);

      // Full 400x300 frame for detection
      const full = document.createElement("canvas");
      full.width = 400;
      full.height = 300;
      const fctx = full.getContext("2d");
      fctx.drawImage(video, 0, 0, 400, 300);
      const fullData = full.toDataURL("image/jpeg", 0.7);

      // Ask server for face box (used only for overlay + metadata)
      await detectFace(fullData);

      ctx.clearRect(0, 0, overlay.width, overlay.height);

      if (lastFace) {
        const f = lastFace;

        // Draw the box and label
        ctx.strokeStyle = resultDiv.style.color || "#00bfff";
        ctx.lineWidth = 3;
        ctx.strokeRect(f.x, f.y, f.w, f.h);

        ctx.font = "bold 16px sans-serif";
        ctx.fillStyle = resultDiv.style.color || "#00bfff";
        const textWidth = ctx.measureText(predictionText).width;
        const textX = f.x + f.w - textWidth - 5;
        const textY = Math.max(f.y + 20, 20);
        ctx.fillText(predictionText, textX, textY);

        // >>> SEND FULL FRAME (scaled to 224x224) to the model <<<
        const frame224 = document.createElement("canvas");
        frame224.width = 224;
        frame224.height = 224;
        const c224 = frame224.getContext("2d");
        c224.drawImage(video, 0, 0, 224, 224);
        const frameData = frame224.toDataURL("image/jpeg", 0.9);

        frames.push(frameData);
        if (frames.length > CLIP) frames.shift();

        // Keep boxes as metadata (not used to crop)
        faceBoxesClip.push({ x: f.x, y: f.y, w: f.w, h: f.h });
        if (faceBoxesClip.length > CLIP) faceBoxesClip.shift();

        if (frames.length === CLIP) {
          await processFrames();
        }
      }
    }, 100);
  };

  stopBtn.onclick = () => {
    clearInterval(interval);
    interval = null;
    ctx.clearRect(0, 0, overlay.width, overlay.height);
    resultDiv.textContent = "";
    predictionText = "";
    frames = [];
    sensors = [];
    faceBoxesClip = [];
    startBtn.disabled = false;
    stopBtn.disabled = true;
    loader.style.display = "none";
    fpsCounter.textContent = "FPS: 0";
  };
</script>

</body>
</html>
